# ChatGPTに絶対に言ってはいけないこと：個人情報のリスクと対策

## 緒言

本レポートでは、PCWorldの記事「Never say these things to ChatGPT. It could come back to bite you」を基に、ChatGPTやその他のAIチャットボットに個人情報を提供することのリスクと、それに対する対策について客観的に分析します。

## AIチャットボットのリスク

AIチャットボットは、ユーザーと自然な会話ができるため、信頼感を与えます。しかし、その裏側ではユーザーが提供した情報がサーバーに保存され、後で再利用される可能性があります。これは、特に個人情報の取り扱いにおいて大きなリスクとなります。

### データの利用と保存

ChatGPTを運営するOpenAIは、利用規約においてユーザーのデータを「モデルを改善するために使用する」と明記しています。これにより、ユーザーがチャットボットに伝えた情報はすべて記録され、AIの学習に利用されます。ただし、プライバシー設定を変更することでチャット履歴の保存を防ぐことが可能です。

### データの漏洩リスク

2023年5月に発生したChatGPTのデータ漏洩事件では、約101,000人のユーザーの個人情報が盗まれました。この事件は、AIチャットボットのセキュリティが完全ではないことを示しています。また、企業でもSamsungがエンジニアが機密情報を誤ってアップロードしたことを受け、ChatGPTの使用を禁止するなど、対策を強化しています。

## 対策と意識の重要性

### プライバシー設定の利用

ChatGPTには、チャット履歴の保存を防ぐプライバシー設定があります。これを有効にすることで、個人情報のリスクを軽減できます。

### 情報の共有を控える

AIチャットボットは便利ですが、個人情報を共有しないことが重要です。特に、金融情報やパスワード、住所、電話番号などの機密情報は絶対に提供しないようにしましょう。

### 政府と業界の動き

最近では、AIチャットボットのリスクに対する意識が高まっており、政府や業界でも対策が進められています。例えば、2023年10月にアメリカのジョー・バイデン大統領が署名したAIに関する大統領令では、AIシステムがプライバシーを尊重し、個人データを保護することを求めています。

## 結論

AIチャットボットは便利なツールですが、個人情報の取り扱いには大きなリスクが伴います。プライバシー設定を利用し、情報の共有を控えることでリスクを軽減することができます。また、政府や業界の動きにも注目し、AI技術の安全な利用を心がけることが重要です。

**元記事:** [Never say these things to ChatGPT. It could come back to bite you PCWorld](https://www.pcworld.com/article/2535401/never-say-these-things-to-chatgpt-it-could-come-back-to-bite-you.html)