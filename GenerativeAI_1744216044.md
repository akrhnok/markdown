# ウェルズ・ファーゴのAIアシスタント「Fargo」：大規模運用とデータ保護の両立

## 1. はじめに

本レポートは、VentureBeatの記事「Wells Fargo’s AI assistant just crossed 245 million interactions – no human handoffs, no sensitive data exposed」を基に、ウェルズ・ファーゴが開発・運用しているAIアシスタント「Fargo」の技術的特徴、運用状況、そして今後の展望について客観的に分析する。本レポートでは、Fargoの成功要因であるデータ保護、大規模運用、そして今後のAI戦略について詳細に検討する。

## 2. Fargoの概要と運用実績

### 2.1. Fargoの機能と利用状況

Fargoは、ウェルズ・ファーゴの顧客が音声またはテキストで利用できるAIアシスタントである。主な機能として、請求書の支払い、資金の移動、取引の詳細の提供、口座に関する質問への回答などが挙げられる。2024年には2億4540万件のインタラクションを処理し、当初の予測を大きく上回る実績を達成した。

### 2.2. 多言語対応と利用者の定着

Fargoは、2023年9月にスペイン語対応を開始し、その利用が急増した。スペイン語の利用率は80%を超えており、多言語対応が顧客の利用促進に大きく貢献していることがわかる。

## 3. データ保護とアーキテクチャ

### 3.1. プライバシーファーストの設計

Fargoは、顧客の機密データを保護するために、プライバシーを最優先に設計されている。具体的には、以下の手順で顧客の情報を処理する。

1. **音声テキスト変換:** 音声によるリクエストは、まずアプリ内でローカルに音声テキスト変換される。
2. **データクレンジングとトークン化:** 変換されたテキストは、ウェルズ・ファーゴの内部システムでクレンジングされ、トークン化される。この段階で、個人を特定できる情報（PII）が検出され、処理される。
3. **意図とエンティティの抽出:** GoogleのFlash 2.0モデルが、ユーザーの意図と関連する情報を抽出するために使用される。
4. **API連携:** 抽出された情報は、ウェルズ・ファーゴのAPIを通じて処理され、LLM（大規模言語モデル）に機密データが直接渡されることはない。

### 3.2. 複合システムとモデルの選択

ウェルズ・ファーゴは、タスクに応じて最適なモデルを選択する「複合システム」を構築している。GoogleのGemini Flash 2.0を主要なモデルとして使用しつつ、Llamaなどの小型モデルやOpenAIのモデルも必要に応じて活用している。

### 3.3. モデルの選択における重要性

ウェルズ・ファーゴのCIOであるChintan Mehta氏は、モデル間の性能差が小さくなっているため、モデルの選択よりも、それらをどのように連携させるか（オーケストレーション）が重要であると述べている。

## 4. 大規模言語モデル（LLM）の活用と課題

### 4.1. 競合との対比

ウェルズ・ファーゴのFargoは、LLMを顧客対応に積極的に活用している点で、競合他社とは異なるアプローチを採用している。例えば、シティは、LLMのハルシネーション（誤情報）やデータセキュリティのリスクを理由に、顧客との直接的な対話を避けている。

### 4.2. エージェント型システムの導入

ウェルズ・ファーゴは、より自律的なシステムを構築するために、エージェント型システムを導入している。例えば、15年分の融資文書を再評価するプロジェクトでは、LangGraphなどのオープンソースフレームワークに基づいた複数のエージェントが連携し、文書の取得、内容の抽出、データのマッチング、計算などのタスクを自動的に実行した。

## 5. Latency（遅延）と価格の重要性

### 5.1. Gemini 2.5 Proの優位性

WayfairのCTOであるFiona Tan氏は、Gemini 2.5 Proの速度の速さを評価しており、特にリアルタイムの顧客向けアプリケーションへの応用を期待している。

### 5.2. 価格と柔軟性

Googleは、Gemini 2.5 Proの価格を競争力のある水準に設定しており、Wayfairは、この価格とタスクに応じた柔軟性を評価している。

## 6. 今後の展望と課題

### 6.1. Google Cloud Nextでの発表

Googleは、年次イベント「Google Cloud Next」で、エージェント型AIに関する新たな機能やツールを発表する予定である。ウェルズ・ファーゴの事例は、GoogleのAI戦略にとって重要な示唆を与えている。

### 6.2. 電力供給の課題

Mehta氏は、AIの普及におけるボトルネックは、モデルの性能やGPUの利用可能性ではなく、電力供給であると指摘している。

## 7. まとめ

ウェルズ・ファーゴのFargoは、データ保護を最優先にしながら、大規模なAIアシスタントを運用することに成功している。その成功の要因は、プライバシーファーストの設計、複合システムによる柔軟なモデル選択、そしてエージェント型システムの導入にある。今後は、電力供給という新たな課題に直面しながら、AI技術の更なる活用を目指していくものと推測される。


**元記事:** [Wells Fargo’s AI assistant just crossed 245 million interactions – no human handoffs, no sensitive data exposed VentureBeat](https://venturebeat.com/ai/wells-fargos-ai-assistant-just-crossed-245-million-interactions-with-zero-humans-in-the-loop-and-zero-pii-to-the-llm/)