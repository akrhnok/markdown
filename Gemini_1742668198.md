# LLMの推論能力を向上させるシンプルなサンプリング手法：GoogleとUC Berkeleyの研究

## 1. はじめに

本レポートでは、Google Researchとカリフォルニア大学バークレー校の研究者らが発表した論文に基づき、大規模言語モデル（LLM）の推論能力を向上させるための新しい手法「サンプリングベースの検索」について分析します。この手法は、複数の応答を生成し、モデル自身で検証を行うというシンプルなアプローチでありながら、既存の高度な手法に匹敵する、あるいはそれを上回る性能を示すことが報告されています。

## 2. 背景：LLMの推論能力向上における課題

LLMの推論能力を向上させるための従来の一般的な手法として、以下の2つが挙げられます。

* **訓練時の工夫:** 強化学習を用いて、思考過程（Chain-of-Thought、CoT）を生成するようにモデルを訓練する方法。
* **推論時の工夫:** モデルが複数の応答を生成し、最も多く出現したものを選択する「自己整合性」などの手法。

これらの手法は有効ですが、訓練に多大なコストがかかったり、複雑な問題への対応に限界があったりするなどの課題がありました。

## 3. サンプリングベースの検索：シンプルなアプローチ

サンプリングベースの検索は、これらの課題に対する新たな解決策として提案されています。その特徴は以下の通りです。

* **シンプルな実装:** ランダムサンプリングと自己検証という、比較的シンプルな手法を採用。
* **高いスケーラビリティ:** 複数の応答を並列に生成できるため、計算リソースを増やすことで性能を容易に向上させることが可能。
* **汎用性:** 特定の推論能力に特化した訓練を受けていないLLMにも適用可能。

### 3.1. サンプリングベースの検索の仕組み

サンプリングベースの検索は、以下の手順で実行されます。

1. **応答生成:** LLMに同じプロンプトを複数回入力し、多様な応答を生成します。
2. **検証:** 各応答に対して、LLM自身がその応答が正しいかどうかを複数回検証します。
3. **スコアリング:** 検証結果を平均化し、各応答の検証スコアを算出します。
4. **応答選択:** 最も高い検証スコアを持つ応答を最終的な回答として選択します。複数の候補が僅差の場合は、LLMにそれらを比較させ、より優れたものを選択します。

### 3.2. サンプリングと検証の重要性

研究では、サンプリング数（応答生成回数）と検証回数を増やすことで、推論性能が向上することが示されています。

## 4. 実験結果：既存手法を超える性能

研究チームは、サンプリングベースの検索を様々なLLMに適用し、その性能を評価しました。その結果、以下の点が明らかになりました。

* **既存手法の性能を超える:** Gemini 1.5 ProなどのLLMにおいて、サンプリングベースの検索を用いることで、推論問題に特化した訓練を受けたo1-Previewの性能を上回りました。
* **スケーラビリティの有効性:** 計算リソースを増やすことで、性能が継続的に向上することが確認されました。

### 4.1. 具体的な性能比較

| モデル | ベンチマーク | サンプリングベース検索の有無 | 性能 

**元記事:** [Less is more UC Berkeley and Google unlock LLM potential through simple sampling VentureBeat](https://venturebeat.com/ai/less-is-more-uc-berkeley-and-google-unlock-llm-potential-through-simple-sampling/)