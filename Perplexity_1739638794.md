# AIニュース報道の正確性に関するBBCの調査

## はじめに

BBCは、AIを利用したニュース報道の正確性を調査しました。この調査では、ChatGPT、Microsoft Copilot、Google Gemini、Perplexity AIなどのAIチャットボットが、ニュースをどのように処理するかを評価しました。結果は、AIがニュース報道において多くの誤りや不正確な情報を提供していることを示しています。

## 調査の概要

- **調査方法**: 45人のBBCのジャーナリストが、100のニュース記事を基にAIチャットボットに質問を出し、回答の正確性を評価しました。
- **評価基準**: 正確性、情報源の示し、偏り、事実と意見の区別、コメント、文脈、BBCコンテンツの適切な処理など7つの要素で評価しました。
- **結果**: 回答の51%に「重大な問題」があり、19%には事実的な誤りが含まれていました[1][2][3]。

## 誤りの例

- **Google Gemini**: イギリスの国民保健サービス（NHS）が「パイリング」を推奨していないと誤って報告しましたが、実際には電子タバコを推奨しています[2][3]。
- **Perplexity AI**: 科学ジャーナリストのマイケル・モスリーの死に関する詳細を捏造しました[2][3]。
- **ChatGPT**: ハマスのリーダーが死亡した後も、彼を現役のリーダーとして紹介しました[2][3]。

## 誤りの原因と影響

- **誤りや捏造**: AIは事実と意見を区別できず、重要な文脈を省略することが多く、誤った情報を提供します[1][2]。
- **影響**: これらの誤りは、特に健康や政治などの重要な分野で、重大な影響を及ぼす可能性があります[2][3]。

## 結論

AIニュース報道の正確性はまだ十分に確保されていないため、AI技術の開発者やメディア企業は、誤りを最小限に抑えるための対策を講じる必要があります。将来的には、AIと人間のエラーレートを比較することで、AIの限界をより明確に理解することが期待されています[2][3]。

#### 参照記事
- [1:https://tmcars.info/post/3818762697/issledovanie-bi-bi-si-cat-boty-s-ii-ne-sposobny-tocno-pereskazyvat-novosti](https://tmcars.info/post/3818762697/issledovanie-bi-bi-si-cat-boty-s-ii-ne-sposobny-tocno-pereskazyvat-novosti)
- [2:https://habr.com/ru/companies/bothub/news/882832/](https://habr.com/ru/companies/bothub/news/882832/)
- [3:https://habr.com/ru/articles/882832/](https://habr.com/ru/articles/882832/)
- [4:https://habr.com/ru/companies/bothub/news/882832/comments/](https://habr.com/ru/companies/bothub/news/882832/comments/)
- [5:https://habr.com/ru/articles/882344/](https://habr.com/ru/articles/882344/)


**元記事:** [Помощники AI не прошли базовую проверку фактов в исследовании BBC News Хабр](https://habr.com/ru/articles/882832/)