# マイクロソフトのCopilotがプライベートなGitHubリポジトリを公開し続ける問題

## 緒言

本レポートでは、マイクロソフトのAIツールであるCopilotがプライベートなGitHubリポジトリのデータを公開し続けている問題について、2025年2月28日の記事を基に客観的に分析します。この問題は、データのプライバシーとセキュリティに重大な影響を及ぼす可能性があります。

## 問題の発端

2024年8月、LinkedInの投稿でChatGPT（および関連するCopilot）がプライベートなGitHubリポジトリのデータにアクセスできると主張されました。この主張が真実であれば、データのセキュリティとプライバシーに大きな影響を与える可能性があります。デジタルセキュリティ会社のLassoがこの問題を調査し、「ゾンビデータ」という現象を発見しました。

## 調査の経過

Lassoの調査は、LinkedInの投稿から始まりました。調査チームは、かつて公開されていたが現在はプライベートに設定されているリポジトリがBingによってインデックスされていたことを発見しました。ChatGPTは直接アクセスするのではなく、Bingのキャッシュからデータを引き出していました。しかし、Copilotはキャッシュされたデータを実際に抽出することができました。これにより、Copilotが外部ツールやシステムによってキャッシュされた「ゾンビデータ」にアクセスしていることが明らかになりました。

## 「ゾンビデータ」のリスク

「ゾンビデータ」は、一時的に公開されたデータがBingのキャッシュなどによって永続的に取得可能であることを指します。このデータは、プライベートに設定された後もアクセス可能であり、特に組織の機密情報が含まれるリポジトリがリスクにさらされます。マイクロソフトのCopilotがBingのキャッシュを利用してこれらのデータにアクセスできることは、データのプライバシーに対する重大な問題を引き起こします。

## 調査結果

LassoはGoogle BigQueryのGitHubアクティビティデータセットを使用して、2024年に一度でも公開されていたが現在はプライベートまたは削除されているリポジトリを特定しました。調査の結果、20,580以上のリポジトリがBingのキャッシュを通じてアクセス可能であることが判明しました。これにより、16,290以上の組織が影響を受け、100以上の脆弱なパッケージと300以上のプライベートな認証情報が公開されました。

## マイクロソフトの対応

Lassoがこの問題をマイクロソフトに報告したところ、マイクロソフトは「低リスク」と評価しつつも、迅速に対応しました。Bingのキャッシュリンク機能を削除し、キャッシュページを保存するcc.bingj.comドメインを無効化しました。しかし、この対策は表面上のものであり、Copilotは依然としてキャッシュされたデータにアクセス可能でした。

## 問題の影響と対策

この問題は、LLM（Large Language Models）の普及により新たな脅威が生じていることを示しています。Lassoは以下の対策を提案しています：

- 一度公開されたデータは永久に漏洩したと考えること
- LLMやAIコパイロットが機密データを公開しないか監視すること
- AIシステムが厳格なアクセス制御を遵守するようにすること
- 基本的なサイバーハイジーンを維持すること

## 結論

マイクロソフトのCopilotがプライベートなGitHubリポジトリのデータを公開し続ける問題は、データのプライバシーとセキュリティに対する重大な脅威です。Lassoの調査結果とマイクロソフトの部分的な対応は、「ゾンビデータ」の問題と生成AIツールの影響力が増していることを示しています。データが重要な時代において、組織はネットワークから出るすべてのデータを管理する必要があります。

**元記事:** [Microsoft Copilot continues to expose private GitHub repositories](https://www.developer-tech.com/news/microsoft-copilot-continues-to-expose-private-github-repositories/)