## 日本政府機関におけるAIツール利用制限：データセキュリティへの懸念と背景

### 1. はじめに

本レポートでは、2025年2月5日に報道された、日本政府機関、特に財務省が職員に対し、ChatGPTやDeepSeekといったAIツールの業務利用を制限する指示を出したというニュース記事に基づき、その背景にあるデータセキュリティへの懸念と、関連する国際的な動向について分析します。

### 2. 報道内容の要約

財務省は、省内のすべての部署に対し、業務で使用するPCやデバイスにおいて、ChatGPTやDeepSeekなどのAIツールやアプリケーションのダウンロードおよび使用を禁止する指示を出しました。その理由として、これらのツールが政府のデータや文書の機密性に対するリスクをもたらす可能性が指摘されています。

### 3. データセキュリティへの懸念

AIツール、特に大規模言語モデル（LLM）は、学習データとして大量の情報を必要とします。職員が業務に関連する情報をこれらのツールに入力した場合、その情報がAIモデルの学習に利用され、結果として機密情報が外部に漏洩するリスクがあります。

具体的には、以下の点が懸念されます。

*   **機密情報の学習データへの混入:** 職員が誤って、または意図的に、機密情報を含むデータをAIツールに入力した場合、その情報がAIモデルの学習データとして利用される可能性があります。
*   **学習済みモデルからの情報漏洩:** 学習済みのAIモデルは、特定のプロンプトに対して、学習データに含まれる情報を出力する可能性があります。
*   **データ管理体制の不透明性:** AIツールを提供する企業が、収集したデータをどのように管理し、利用しているかについて、透明性が確保されていない場合があります。

### 4. 国際的な動向

記事では、オーストラリアやイタリアといった国々が、中国のDeepSeekに対して、プライバシーやデータ安全保障上の懸念から、公的システムでの利用を制限していることが言及されています。これは、AIツールの利用におけるデータセキュリティへの懸念が、国際的な共通認識となっていることを示唆しています。

### 5. DeepSeekの台頭とAI市場の競争激化

DeepSeekは、OpenAIのChatGPTと比較して、低コストで高性能なAIモデルを提供していることで注目を集めています。記事によると、DeepSeekの最新AIモデルの開発コストは600万ドルであり、これは一般的なAIモデルの開発コストである数十億ドルと比較して、非常に低い水準です。また、DeepSeekのR1は、ChatGPTなどの既存のAIモデルと比較して、少ない計算能力で動作します。

DeepSeekの台頭は、AI市場における競争の激化を象徴しています。低コストで高性能なAIモデルの登場は、AI技術の普及を加速させる一方で、データセキュリティや倫理的な問題に対する懸念も高めています。

### 6. まとめ

財務省によるAIツール利用制限の指示は、政府機関におけるデータセキュリティの重要性を示すものです。AI技術の利用は、業務効率の向上や新たな価値創造につながる可能性がありますが、同時に、機密情報の漏洩やプライバシー侵害といったリスクも伴います。

政府機関は、AI技術の利用にあたり、データセキュリティに関するリスクを十分に評価し、適切な対策を講じる必要があります。また、AIツールを提供する企業は、データ管理体制の透明性を高め、ユーザーのプライバシーを保護するための取り組みを強化する必要があります。

**元記事:** [FinMin Directs Officers Not to Use ChatGPT, DeepSeek, Other AI Models Flagging Data Risk Concerns](https://www.outlookbusiness.com/economy-and-policy/finmin-directs-officers-not-to-use-chatgpt-deepseek-other-ai-models-flagging-data-risk-concerns)