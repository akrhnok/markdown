# AI時代における厳格責任：FDCA遵守のための人的監督の重要性

## 緒言

本レポートでは、AI（人工知能）の急速な進化がもたらす新たな法的課題、特に食品・医薬品・化粧品法（FDCA）への影響について、Hogan Lovellsの論文を基に客観的に分析する。AIの利用が増える中、企業の責任者に対する厳格責任の適用と人的監督の必要性が強調されている。

## AIとFDCAの関係

### 主要な技術用語

AIは、人間と同様の知能を持つシステムを開発する広範な分野です。以下に主要な技術用語を説明します。

- **AI（人工知能）**：機械ベースのシステムが予測、推奨、または意思決定を行う技術。
- **アルゴリズム**：特定のタスクを実行するためのステップバイステップの指示。
- **機械学習（ML）**：アルゴリズムを訓練し、時間と共に改善させる技術。
- **生成AI**：新しいコンテンツ（テキスト、芸術、音楽など）を作成する技術。

### FDCAと責任者責任原則（RCOD）

FDCAは、食品、医薬品、医療機器、化粧品の安全性を確保するための法律です。この法律は厳格責任を採用しており、違反行為の認識や意図がなくても責任を問われる可能性があります。特に、責任者責任原則（RCOD）は、企業の責任者が違反を防ぐ立場にあったにもかかわらずそれを怠った場合、責任を負うことを示しています。

### サルモネラ汚染卵の事例

サルモネラ汚染卵の事例では、企業の責任者が汚染を知らなかったとしても、違反行為を防ぐ立場にあったため、厳格責任が適用されました。この事例は、AIの出力に関する知識がなくても、企業の責任者がFDCA違反で訴追される可能性があることを示しています。

## DOJのAIに対する取り組み

米国司法省（DOJ）は、AIの利用が増える中、新たな刑事責任の理論を追求しています。特に、AIの誤用により犯罪がより危険になる場合、厳罰を求める方針を示しています。また、AIの潜在的なリスクを理解し、適切に管理するための「Justice AI」イニシアチブを発表しています。

## リスクの軽減策

AIの利用が増える中、企業は以下の対策を講じることが推奨されます。

- **トレーニングデータセットの確認**：AIシステムの入力データを定期的に確認し、問題がないかを確認します。
- **AIシステムとその出力のテスト**：AIシステムが正しく機能しているかをテストし、出力が適切であるかを確認します。
- **リスク軽減のためのコントロールの見直し**：AIシステムが望ましくない出力（例：FDCA違反行為）を引き起こすリスクを軽減するためのコントロールを定期的に見直します。
- **人的介入の重要性**：AIの進化が速い中でも、人的介入による定期的な監視がリスク軽減の重要な手段となります。

## 結論

AIの急速な進化は、企業の責任者に対する厳格責任の適用を新たな形で引き起こす可能性があります。特にFDCAの遵守においては、人的監督が不可欠であり、企業はAIの利用に伴うリスクを適切に管理する必要があります。

**元記事:** [Strict liability in the age of AI Why human oversight is crucial for FDCA compliance - Lexology](https://www.lexology.com/library/detail.aspx?g=dfa5bb20-5a7e-4ec7-bf3f-d605e2f7266e)