## インド財務省が職員にChatGPTなどのAIツールの使用を禁止：政府データの機密性リスクを懸念

### 1. はじめに

本レポートでは、ロイター通信が2025年2月5日に報じた記事に基づき、インド財務省が職員に対し、ChatGPTやDeepSeekといったAIツールの業務利用を禁止した背景と、その影響について客観的に分析する。政府機関におけるAIツール利用に関する機密性リスクへの懸念が高まる中、インドの事例は他国にも影響を与える可能性がある。

### 2. 報道の概要

インド財務省は、政府文書やデータの機密性に対するリスクを理由に、職員に対しChatGPTやDeepSeekなどのAIツールの業務利用を禁止する内部通達を出した。同様の措置は、データセキュリティリスクを理由にオーストラリアやイタリアでも講じられている。この通達は、OpenAIのCEOであるサム・アルトマン氏がインドを訪問し、IT大臣との会談を予定しているタイミングで発表された。

### 3. 禁止の背景

インド財務省がAIツールの利用を禁止した主な理由は、以下の通りである。

*   **政府データの機密性リスク:** AIツールに政府の機密情報が入力されることで、情報漏洩のリスクが高まる。
*   **データセキュリティへの懸念:** AIツールが収集・利用するデータの管理体制やセキュリティ対策に対する不透明性。

これらのリスクを考慮し、インド財務省は職員に対し、業務においてAIツールを使用しないよう指示した。

### 4. AIツール利用禁止の影響

インド財務省によるAIツール利用禁止は、以下の影響が考えられる。

*   **業務効率の低下:** AIツールを活用することで効率化されていた業務において、代替手段を検討する必要が生じる。
*   **イノベーションの阻害:** AI技術の活用による新たなサービスや業務プロセスの開発が遅れる可能性がある。
*   **他省庁への影響:** インド財務省の決定が、他の政府機関におけるAIツール利用に関する議論を活発化させる可能性がある。

### 5. OpenAIの状況

OpenAIは、インドの主要メディア企業との間で著作権侵害に関する訴訟を抱えている。OpenAIは、インド国内にサーバーを設置していないため、インドの裁判所は本件を審理すべきではないと主張している。

### 6. 各社の反応

インド財務省、ChatGPTを開発するOpenAI、DeepSeekの各社は、本件に関するコメントを控えている。

### 7. まとめ

インド財務省によるAIツール利用禁止は、政府機関におけるデータセキュリティと機密性保護の重要性を示す事例である。AI技術の発展に伴い、その利用に関するリスク管理の必要性が高まっている。今後、各国政府は、AI技術の利活用とリスク管理のバランスをどのように取るかが課題となるだろう。


**元記事:** [India's finance ministry asks employees to avoid AI tools like ChatGPT, DeepSeek | Reuters](https://www.reuters.com/technology/artificial-intelligence/indias-finance-ministry-asks-employees-avoid-ai-tools-like-chatgpt-deepseek-2025-02-05/)