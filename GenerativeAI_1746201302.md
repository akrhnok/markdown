## 主要LLMを脅かす新手のプロンプトインジェクション「Policy Puppetry」が登場！

### 記事の主要ポイント

* **Policy Puppetryとは:** 主要なLLM（ChatGPT、Claude、Geminiなど）の安全対策を回避し、有害な出力を引き出すプロンプトインジェクション手法。
* **汎用性と転送可能性:** 単一のテンプレートで複数のLLMに有効であり、これまでの個別対応型攻撃とは一線を画す。
* **攻撃の仕組み:** モデルに「設定情報」と誤認識させ、ロールプレイとエンコードを組み合わせることで、ガードレールをすり抜ける。
* **危険性:** 生物兵器の作り方、自殺の方法、違法薬物の合成方法など、本来出力が制限されるはずの情報を生成可能にする。

### 詳細解説

HiddenLayer社が発表した「Policy Puppetry」は、大規模言語モデル（LLM）の安全性を脅かす新たなプロンプトインジェクション手法です。この手法は、ChatGPT、Claude、Gemini、Copilot、LLaMAなど、主要な生成AIモデルすべてに対して有効であり、単一のテンプレートで複数のモデルを攻撃できるという点で、これまでの攻撃とは一線を画しています。

Policy Puppetryの核心は、LLMに「誤認識」を起こさせることにあります。具体的には、プロンプトをXML/JSON形式の構成ファイルに見せかけ、ロールプレイ（役割演技）とエンコード（leet speakなど）を組み合わせることで、モデルの安全対策を回避します。これにより、モデルは通常のユーザー入力ではなく「構成設定データ」と誤って認識し、システムプロンプトで定義された制限や倫理的制御を無視して、有害な情報を生成してしまうのです。

| 特徴 | Policy Puppetry 

**元記事:** [主要なLLMに有効なプロンプト インジェクション「Policy Puppetry」-サイバー攻撃への悪用が容易セキュリティとAIのニュース](https://rocket-boys.co.jp/security-measures-lab/policy-puppetry-prompt-injection-targets-major-llm/)