# ChatGPTの誤情報問題：LGBTQ+に関する情報の正確性に関する調査レポート

## 1. はじめに

本レポートは、オンラインメディア「Them」に掲載された記事「ChatGPT Inaccurately Reported That Straight Public Figures Are Gay, Study Finds」を基に、大規模言語モデル（LLM）であるChatGPTがLGBTQ+（レズビアン、ゲイ、バイセクシュアル、トランスジェンダー、クィアなど性的少数者の総称）に関する情報において誤った情報を提示する問題について分析します。本レポートでは、記事で紹介されている研究結果を詳細に検討し、その影響と課題について考察します。

## 2. 研究の概要

### 2.1. 研究の目的と方法

本研究は、アイルランドのダブリン大学（University College Dublin, UCD）の研究者によって実施され、ChatGPT（バージョン3.5）がLGBTQ+に関する情報について、正確な情報を提供できるかを検証することを目的としています。研究では、インドとアイルランドの参加者に対し、LGBTQ+に関連する質問をGoogleとChatGPTで検索させ、その結果を比較しました。

### 2.2. 主な調査結果

研究の結果、ChatGPTは、ストレートの公人（公に異性愛者であることを公言している人物）をゲイであると誤って報告したり、存在しないLGBTQ+の人物を作り出すなど、誤った情報を頻繁に提供することが明らかになりました。一方、Google検索では、より正確な情報が得られる傾向がありました。

| 検索エンジン | 正答率（例） 

**元記事:** [ChatGPT Inaccurately Reported That Straight Public Figures Are Gay, Study Finds Them](https://www.them.us/story/chat-gpt-straight-public-figures-gay-false-information)