## AIの進化と「幻覚」問題：最新AIは強力になるほど嘘をつく？

### 記事の主要ポイント

* 最新のAIシステムは、その能力が向上する一方で、誤った情報を生成する「幻覚」と呼ばれる現象が深刻化している。
* OpenAIなどの企業が開発した「推論」システムは、数学的スキルは向上しているものの、事実に基づいた情報処理能力は低下している。
* AIは膨大なデータから学習するが、真偽を判断する能力を持たないため、誤った情報を生成してしまう。
* AIの「幻覚」は、技術的な限界であり、完全に解消することは難しいと考えられている。

### 詳細解説

最新のAI技術は目覚ましい進化を遂げていますが、その一方で、誤った情報を生成してしまう「幻覚」と呼ばれる問題が深刻化しています。これは、AIが膨大なデータから学習する際に、真偽を判断する能力を持たないことが原因です。例えば、プログラミングツールCursorのAIサポートボットが、存在しない利用制限を発表し、ユーザーに混乱を招いた事例が報告されています。

最新のAIシステムは、数学的な能力は向上しているものの、事実に基づいた情報処理能力は低下している傾向があります。これは、AIが確率に基づいて最適な回答を生成するため、誤った情報を生成してしまう可能性が高まるためです。あるテストでは、最新のAIシステムの「幻覚」発生率が79%に達したという報告もあります。

| 特徴 | 従来のAI | 最新のAI（推論システム） |
|---|---|---|
| **能力** | 特定のタスクに特化 | より複雑なタスクに対応、推論能力 |
| **問題点** | 誤情報生成の可能性は低い | 誤情報生成（幻覚）の可能性が高い |
| **学習方法** | 規則に基づいた学習 | 大量のデータからの学習 |
| **真偽判断** | できない | できない |

### まとめ

AI技術は日々進化していますが、その進化に伴い「幻覚」と呼ばれる問題が深刻化しています。これは、AIが真偽を判断する能力を持たないことによるもので、技術的な限界として認識されています。AIの利用においては、生成された情報の正確性を常に注意深く確認する必要があるでしょう。

### 元記事へのリンク

[A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful - The New York Times](https://www.nytimes.com/2024/05/05/technology/ai-hallucinations.html)


**元記事:** [A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful - The New York Times](https://www.nytimes.com/2025/05/05/technology/ai-hallucinations-chatgpt-google.html)