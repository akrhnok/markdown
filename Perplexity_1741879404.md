## AIチャットボットのニュース検索精度に関する調査レポート

### 1. はじめに

本レポートは、2025年3月13日に公開された記事「Inteligência artificial erra na maioria das consultas – e com convicção（AIはほとんどの場合で間違える - しかも確信を持って）」を基に、AIチャットボットのニュース検索精度に関する調査結果を分析するものである。本調査は、AIチャットボットがニュース記事の引用に基づいて検索を行う際の精度を評価し、その課題を明らかにすることを目的としている。

### 2. 調査概要

#### 2.1. 調査対象

本調査では、以下の8つのAIチャットボットが評価対象となった。

* ChatGPT
* Perplexity
* Perplexity Pro
* DeepSeek
* Copilot
* Grok-2
* Grok-3
* Gemini

#### 2.2. 調査方法

各チャットボットに対し、ニュース記事の引用に基づいた200件のプロンプト（質問）が与えられた。プロンプトには、記事のタイトル、公開日、媒体名、URL、および記事からの別の引用が含まれていた。チャットボットは、これらの情報に基づいて回答を生成する必要があった。

#### 2.3. 回答の評価基準

チャットボットの回答は、以下の6つのカテゴリーに分類された。

* **正確:** すべての要求事項が満たされた回答
* **正確だが不完全:** 一部の情報が正確だが、情報が不足している回答
* **部分的に不正確:** 一部の情報が正確で、一部が不正確な回答
* **完全に不正確:** すべての情報が不正確な回答
* **無回答:** チャットボットが回答しなかった場合
* **ブロック:** 媒体がAIによるアクセスをブロックした場合

### 3. 調査結果

#### 3.1. 各チャットボットのパフォーマンス

| チャットボット | エラー率 (%) |
| :-------------------- | :-----------: |
| Grok-3 | 94 |
| Perplexity (無料版) | 35 |

Grok-3は、94%という高いエラー率を示し、最もパフォーマンスが低い結果となった。一方、Perplexityの無料版は、35%のエラー率と最も高い精度を示した。

#### 3.2. その他の問題点

* **リンク切れ:** 多くのチャットボットが、エラーページや元の記事と重複するコンテンツへのリンクを提示した。Grok-3は117件、Geminiは127件のリンク切れの問題があった。
* **プレミアム版の誤り:** プレミアム版のチャットボット（Grok-3、Perplexity Proなど）は、無料版よりも誤りが多い傾向が見られた。
* **確信的な誤り:** プレミアム版は、誤った情報をより確信的に提示する傾向があり、ユーザーが情報の信頼性を判断することを困難にしている。
* **無回答:** Copilotは、質問に対して回答を拒否する傾向が最も高かった。

#### 3.3. 全体的な結果

本調査の結果、AIチャットボットは、60%以上の検索で誤った回答を生成していることが明らかになった。

### 4. 企業側の対応

本調査に対し、OpenAI（ChatGPTの開発元）とMicrosoft（Copilotの開発元）がコメントを発表した。OpenAIは、ChatGPTが質の高いコンテンツの発見を支援し、引用の精度向上に努めていると述べた。Microsoftは、robots.txtの標準を尊重し、サイトの指示に従っていると表明した。

### 5. 結論

本調査は、AIチャットボットのニュース検索精度に課題があることを示している。特に、Grok-3のような一部のチャットボットは、高いエラー率を示した。また、プレミアム版が無料版よりも誤りが多い傾向や、誤った情報を確信的に提示する問題も確認された。AI技術の発展に伴い、これらの課題の克服が重要となる。


**元記事:** [Inteligência artificial erra na maioria das vezes - e com convicção](https://olhardigital.com.br/2025/03/13/pro/inteligencia-artificial-erra-na-maioria-das-consultas-e-com-conviccao/)