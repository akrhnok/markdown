# OpenAIとDeepSeekを巡るコード盗用疑惑とOpenAIの対応策

## 1. はじめに

本レポートは、2025年4月18日にHindustan Timesに掲載された記事「OpenAI's new move amid claims that DeepSeek copied its code」を基に、OpenAIと中国のAI企業DeepSeekを巡るコード盗用疑惑と、OpenAIが講じた対応策について分析する。記事は、DeepSeekのAIモデルDeepSeek-R1がOpenAIのモデルのコードを盗用した疑いがあるとし、OpenAIが開発者向けに導入した本人確認制度について言及している。

## 2. DeepSeek-R1のコード盗用疑惑

### 2.1. Copyleaksによる調査結果

記事によると、AIコンテンツ検出企業Copyleaksの調査結果として、DeepSeek-R1の出力の74.2%がOpenAIのモデルによって生成されたものと分類されたという。この結果は、DeepSeek-R1がOpenAIのモデルのコードを不正に利用している可能性を示唆している。

### 2.2. 類似性の評価方法

Copyleaksは、Claude、Gemini、Llama、OpenAIのテキストで訓練された3つのAI分類器を組み合わせ、文章構造、語彙、言い回しなどの微妙なスタイルの特徴を識別した。この分類器は、99.88%の精度と0.04%の誤検出率を誇るとしている。

### 2.3. 他のモデルとの比較

Copyleaksは、Microsoftのphi-4やElon MuskのGrok-1などの他のモデルについてもテストを実施した。その結果、これらのモデルはOpenAIとの類似性がほとんどなく、独立して訓練されたことが示唆された。一方、MistralのMixtralモデルにはある程度の類似性が見られたものの、DeepSeekの数値は際立って高かったという。

## 3. OpenAIの対応策

### 3.1. 開発者向け本人確認制度の導入

OpenAIは、自社の最先端AIモデルへのアクセスを希望する開発者に対し、政府発行のIDによる本人確認を義務付ける措置を講じた。これは、OpenAIの利用規約に違反してAPIを不正利用する開発者を排除するためとされている。

### 3.2. 本人確認の目的

OpenAIは、本人確認制度の導入について、「少数の開発者が意図的にOpenAIのAPIを不正利用している」ためと説明している。

### 3.3. 本人確認後のアクセス

本人確認が完了した開発者は、o1、o3-mini、o3、o4-miniからのReasoning Summariesにアクセスできるようになる。

### 3.4. 対応国

OpenAIは、200以上の国からの本人確認に対応していると述べているが、具体的なリストは公開していない。

## 4. 考察

### 4.1. コード盗用の影響

DeepSeekによるコード盗用疑惑が事実であれば、AI業界における知的財産権侵害の問題が浮き彫りになる。また、DeepSeekがOpenAIの技術を不正に利用して低コストで高性能なモデルを開発した場合、市場競争の公平性を損なう可能性がある。

### 4.2. OpenAIの対応策の意義

OpenAIが導入した本人確認制度は、自社の技術を保護し、不正利用を防ぐための有効な手段となり得る。しかし、この措置は、開発者にとってアクセスへのハードルを高める可能性もある。

### 4.3. AI技術開発における倫理的課題

AI技術の開発においては、データの利用、知的財産権、透明性といった倫理的な課題が重要となる。今回の事例は、AI技術の急速な発展に伴い、これらの課題への対応が急務であることを示唆している。

## 5. まとめ

本レポートでは、OpenAIとDeepSeekを巡るコード盗用疑惑と、OpenAIの対応策について分析した。DeepSeek-R1のコード盗用疑惑は、AI業界における知的財産権の問題を提起しており、OpenAIの本人確認制度は、自社の技術を保護するための措置として評価できる。AI技術の発展に伴い、倫理的な課題への対応が不可欠であり、今後の動向を注視する必要がある。


**元記事:** [OpenAI's new move amid claims that DeepSeek copied its code - Hindustan Times](https://www.hindustantimes.com/business/openais-new-move-amid-claims-that-deepseek-copied-its-code-101744855054216.html)