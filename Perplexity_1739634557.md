# AIニュースリポートの正確性に関するBBCの調査

## はじめに

BBCは、AIを利用したニュースリポートの正確性を調査しました。この調査では、ChatGPT、Microsoft Copilot、Google Gemini、Perplexity AIなどのAIツールが、ニュース記事をどのように処理し、どれほど正確に情報を提供できるかを評価しました。ここでは、この調査の結果を詳しく見ていきます。

## 調査の方法と結果

- **調査方法**: 45人のBBCのジャーナリストが、100のニュース記事をAIツールに提供し、それに対する質問に答えてもらいました。回答は、正確性、情報源の示し方、偏り、事実と意見の区別、コメント、文脈、BBCコンテンツの適切な処理という7つの基準で評価されました[2][3]。

- **結果**: AIツールの回答の51%に「重大な問題」が見つかりました。これには、基本的な事実の誤りや完全に捏造された情報が含まれます。特に、BBCのコンテンツを引用する際には、19%の回答に誤りがあり、13%には捏造されたまたは誤って帰属された引用がありました[2][3]。

## 誤りや問題点の具体例

- **Google Gemini**: イギリスの国民保健サービス（NHS）が「パイリング」を推奨していないと誤って報告しましたが、実際にはNHSは電子タバコを推奨しています[2][3]。

- **Perplexity AI**: 科学ジャーナリストのマイケル・モスリーの死に関する詳細を捏造しました[2][3]。

- **ChatGPT**: ハマスのリーダーの死を認識せず、依然として現役のリーダーであると述べました[2][3]。

## 課題と今後の展望

- **課題**: AIツールは、事実と意見を区別しにくく、重要な文脈を省略する傾向があります。また、古い情報を最新のニュースとして提示することもあります[2][3]。

- **今後の展望**: BBCは今後もこの調査を繰り返し、独立したレビューアーを参加させることで、AIと人間の違いをより明確に示すことを計画しています[2][3]。また、AIの誤りを完全に把握することは難しいと指摘し、規制が必要であると強調しています[3]。

## 結論

AIニュースリポートは便利ですが、正確性に問題があります。BBCの調査は、これらの問題を浮き彫りにし、今後の改善の必要性を示しています。AI技術の進化とともに、正確な情報提供が求められます。

#### 参照記事
- [[1]:https://tmcars.info/post/3818762697/issledovanie-bi-bi-si-cat-boty-s-ii-ne-sposobny-tocno-pereskazyvat-novosti](https://tmcars.info/post/3818762697/issledovanie-bi-bi-si-cat-boty-s-ii-ne-sposobny-tocno-pereskazyvat-novosti)
- [[2]:https://habr.com/ru/companies/bothub/news/882832/](https://habr.com/ru/companies/bothub/news/882832/)
- [[3]:https://habr.com/ru/articles/882832/](https://habr.com/ru/articles/882832/)
- [[4]:https://habr.com/ru/news/](https://habr.com/ru/news/)
- [[5]:https://habr.com/ru/articles/882344/](https://habr.com/ru/articles/882344/)


**元記事:** [Помощники AI не прошли базовую проверку фактов в исследовании BBC News Хабр](https://habr.com/ru/articles/882832/)