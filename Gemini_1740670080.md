# GoogleとUnbabelがWMT24++でAI翻訳ベンチマークを55言語に拡大

## 緒言

GoogleとUnbabelの研究者たちは、WMT24++という新しいデータセットを発表しました。これにより、機械翻訳（MT）のベンチマークが9言語から55言語に拡大されました。このレポートでは、WMT24++の詳細とその意義について客観的に分析します。

## WMT24++の概要

### 言語カバレッジの拡大

WMT24++は、WMT24のベンチマークを大幅に拡張し、9言語から55言語へとカバー範囲を広げました。新たに追加されたのは46言語で、これらの言語に対しても人間の翻訳者による参照翻訳と後編集が含まれています。また、オリジナルの9言語のうち8言語に対しても新しい後編集が行われました。

### データセットの構成

WMT24++は、文学、ニュース、ソーシャルメディア、音声の4つの領域をカバーしています。データセットの作成には、プロの言語学者が参加し、彼らは居住地域に応じた適切な報酬を受け取りました。

## 大規模言語モデルの評価

### ベンチマークの重要性

研究者たちは、大規模言語モデル（LLM）の多言語性能を評価するためにベンチマークデータセットの収集が重要であると強調しています。特に、機械翻訳の分野では、英語以外の言語での性能評価が求められています。

### LLMの優位性

WMT24++を用いた評価では、LLMが従来のMTシステムを全ての55言語で上回る結果を示しました。特に、OpenAIのo1、GoogleのGemini-1.5 Pro、AnthropicのClaude 3.5がトップパフォーマンスを発揮し、Google Translate、DeepL、Microsoft Translatorなどの従来のMTプロバイダーを上回りました。

## 自動評価と人間の評価

### 自動評価の限界

自動評価ではLLMが優れた結果を示しましたが、研究者たちは自動評価の限界を指摘しています。自動評価メトリックは、人間の翻訳に対してバイアスを持つ可能性があり、55言語の多くでその有効性が未検証であると述べています。

### 人間の評価の必要性

研究者たちは、人間の評価が実際の翻訳品質を評価し、LLMの限界を理解するために不可欠であると強調しています。将来的には、大規模な人間の評価を実施してこれらの結果を検証する予定です。

## データセットの公開と応用

### データセットの公開

WMT24++はHugging Faceで公開されており、研究者や開発者が自由に利用できます。また、利用可能なソース画像も保持されており、多モーダル翻訳研究をサポートすることを目指しています。

## 結論

GoogleとUnbabelによるWMT24++の発表は、機械翻訳のベンチマークを大幅に拡大し、多言語の大規模言語モデルの性能評価に新たな道を開きました。しかし、自動評価の限界を考慮し、人間の評価が引き続き重要であることを認識する必要があります。このデータセットは、多言語翻訳の研究と開発に大きな貢献をもたらすことでしょう。

**元記事:** [Google, Unbabel Expand Key AI Translation Benchmark to 55 Languages with WMT24++ - Slator](https://slator.com/google-unbabel-expand-key-ai-translation-benchmark-55-languages-wmt24/)