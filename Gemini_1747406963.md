### GoogleがAndroidとChromeの新しいAIアクセシビリティツールを発表

#### 主要ポイント:
- GoogleがAndroidとChromeのAIアクセシビリティツールを更新
- Gemini AIがTalkBackに統合され、画像やスクリーン上のコンテンツに関する質問に答える
- Expressive Captionsが音声のニュアンスを捉えるキャプションを生成
- Project Euphoniaが世界規模で非典型的なスピーチパターンの認識をサポート
- 学生向けのアクセシビリティ機能が強化

#### 詳細な解説:
Googleは、Global Accessibility Awareness Dayを記念して、AndroidとChromeのアクセシビリティツールを更新しました。Androidの製品管理ディレクター、Angana Ghosh氏は、視覚や聴覚に障害のあるユーザー向けに、Gemini AIを含むAI技術を組み合わせてコアモバイル機能を改善していると述べました。特に、Gemini AIは昨年TalkBackに導入され、画像の説明を提供していましたが、今回の更新により、ユーザーは写真やスクリーン上のコンテンツについて質問し、詳細な回答を得ることができるようになりました。例えば、ギターの写真が共有された場合、その種類や色について質問することが可能です。

また、Expressive Captionsは、多くのAndroidアプリで音声のニュアンスを捉えるライブキャプションを生成します。この機能は、伸ばされた音（例えば「nooooo」や「amaaazing shot」）や口笛、喉を鳴らす音なども認識します。現在、この機能は英語で展開されており、Android 15以降を搭載したデバイスを持つアメリカ、イギリス、カナダ、オーストラリアのユーザーが利用できます。

さらに、Googleは2019年に開始したProject Euphoniaを通じて、非典型的なスピーチパターンの認識を世界規模でサポートしています。開発者は、Project EuphoniaのGitHubページで提供されているオープンソースリソースを使用して、パーソナライズされた音声ツールや多様なスピーチパターンに合わせたスピーチ認識モデルを構築できます。また、Google.orgとUniversity College Londonが共同で設立したCentre for Digital Language Inclusion (CDLI)は、10のAfrican言語のオープンデータセットを開発し、スピーチ認識技術を構築しています。

#### まとめ:
Googleは、AndroidとChromeのアクセシビリティを強化するための新しいAIツールを発表しました。これらのツールは、視覚や聴覚に障害のあるユーザーや非典型的なスピーチパターンを持つ人々にとって非常に有益です。また、学生向けのアクセシビリティ機能も強化され、教育環境での利用が促進されています。

#### 元記事へのリンク:
[Google rolls out new AI tools to improve accessibility on Android and Chrome](リンク先URL)

**元記事:** [Google rolls out new AI tools to improve accessibility on Android and Chrome](https://www.fonearena.com/blog/453766/google-new-ai-tools-android-chrome.html)