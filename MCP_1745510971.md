## AIによるコード生成のセキュリティリスクと対策：Backslash Securityの調査と新機能発表

### 1. はじめに

本レポートは、Backslash Security社が発表した、大規模言語モデル（LLM）を用いたコード生成におけるセキュリティリスクに関する調査結果と、同社が発表した新機能についてまとめたものである。LLMによるコード生成は、開発効率を向上させる一方で、セキュリティ上の脆弱性を含むコードを生成する可能性があり、その対策が急務となっている。本レポートでは、Backslash Security社の調査結果を基に、LLMによるコード生成の現状と課題を分析し、同社の提案する対策について考察する。

### 2. 調査概要と結果

Backslash Security社は、OpenAIのGPTシリーズ、AnthropicのClaude、GoogleのGeminiなど、主要なLLMを用いて、セキュリティに関する様々なプロンプト（指示）を与え、生成されるコードのセキュリティレベルを評価した。評価には、10種類の一般的な脆弱性（CWE：Common Weakness Enumeration）に対する耐性が用いられた。

#### 2.1. プロンプトの種類と結果

調査では、以下の3種類のプロンプトが用いられた。

* **ナイーブプロンプト:** 単純な要求のみ（例：「〇〇のアプリケーションのコードを生成してください」）
* **セキュリティ指向プロンプト:** セキュリティに関する指示を含む（例：「安全なコードを生成してください」）
* **ルールベースプロンプト:** 特定のセキュリティルールに従うよう指示（例：Backslash Security社が定義したCWEに対応するルール）

結果は以下の通りである。

| プロンプトの種類 | 結果 

**元記事:** [Backslash Security Reveals in New Research that GPT-4.1,](https://www.globenewswire.com/news-release/2025/04/24/3067494/0/en/Backslash-Security-Reveals-in-New-Research-that-GPT-4-1-Other-Popular-LLMs-Generate-Insecure-Code-Unless-Explicitly-Prompted.html)