## LLMの推論能力を向上させるシンプルな手法：GoogleとUC Berkeleyの研究成果

### 1. はじめに

本レポートでは、Google Researchとカリフォルニア大学バークレー校の研究者らが発表した論文を基に、大規模言語モデル（LLM）の推論能力を向上させるための新しい手法について分析します。この手法は、複雑なモデル構造や大規模な学習を必要とせず、シンプルなサンプリングベースの検索（sampling-based search）を用いることで、高いパフォーマンスを実現しています。

### 2. 現状のLLMにおける推論能力向上の課題

LLMの推論能力を向上させるための既存の手法には、主に以下の2つがあります。

* **CoT（Chain-of-Thought）:** モデルを訓練し、思考の過程を段階的に生成させることで、より長い回答を生成させる方法です。OpenAIのo1やDeepSeek-R1などのモデルで採用されていますが、訓練に多大なコストがかかります。
* **自己整合性（Self-Consistency）:** 複数の回答を生成し、最も多く出現した回答を選択する方法です。しかし、複雑な問題においては、最も多く出現した回答が必ずしも正解とは限らないという限界があります。

### 3. サンプリングベースの検索：シンプルで効果的な代替手法

サンプリングベースの検索は、LLMに複数の回答を生成させ、検証メカニズムを用いて最適な回答を選択する手法です。この手法は、以下の特徴を持ちます。

* **シンプルさ:** 複雑なモデル構造や大規模な学習を必要としません。
* **スケーラビリティ:** 複数の回答を並列に生成できるため、計算リソースを増やすことで容易に性能を向上させることができます。
* **汎用性:** 推論能力のために特別に訓練されていないLLMにも適用できます。

### 4. サンプリングベースの検索の仕組み

研究者らは、LLMを用いて候補となる回答を生成し、それらを検証する「自己検証」プロセスに焦点を当てた、シンプルなサンプリングベースの検索を提案しています。

1. **回答候補の生成:** LLMに同じ質問を複数回提示し、温度パラメータ（temperature setting）を調整することで、多様な回答候補を生成します。
2. **検証:** 各回答候補に対して、LLMに複数回質問を行い、その回答が正しいかどうかを検証します。検証結果を平均化して、最終的な検証スコアを算出します。
3. **回答の選択:** 最も高い検証スコアを持つ回答を最終的な答えとして選択します。複数の回答候補のスコアが近い場合は、LLMにそれらを比較させ、最も優れているものを選択します。

### 5. 実験結果と評価

研究者らは、サンプリング数と検証回数を変化させながら実験を行い、以下の結果を得ました。

* **性能向上:** サンプリングベースの検索は、自己整合性が飽和する点を超えても、推論能力を向上させることが確認されました。
* **Gemini 1.5 Proの性能向上:** Gemini 1.5 Proの性能は、推論問題に特化した訓練を受けたo1-Previewの性能を超えました。
* **Gemini 1.5 Flashの性能向上:** Gemini 1.5 Flashは、Gemini 1.5 Proよりもさらに高い性能を示しました。

| モデル | ベンチマーク例 | 性能（例） 

**元記事:** [Less is more UC Berkeley and Google unlock LLM potential through simple sampling VentureBeat](https://venturebeat.com/ai/less-is-more-uc-berkeley-and-google-unlock-llm-potential-through-simple-sampling/)