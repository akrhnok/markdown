# 17人の医師が見抜けなかった病を、AIが診断：ChatGPTが母親を助けた稀な症例

## 1. はじめに

本レポートは、2025年4月15日にNews18 English Editionで公開された記事「When 17 Doctors Fell Short, AI Stepped Up: How ChatGPT Helped A Mother Diagnose Son's Rare Condition」を基に、その内容を客観的に分析し、まとめたものである。本記事は、人工知能（AI）チャットボットであるChatGPTが、17人の医師が見抜けなかった病気を診断する上で、どのように役立ったかという事例を紹介している。

## 2. 事例の概要

アメリカ人女性であるCourtneyは、4歳の息子Alexの病状について、3年間もの間、原因を特定できずにいた。様々な専門医に相談したが、診断には至らなかった。そこで、CourtneyはChatGPTを利用することにした。息子のMRI検査結果と症状をChatGPTに入力したところ、ChatGPTは「Tethered Cord Syndrome（脊髄係留症候群）」という稀な神経疾患の可能性を示唆した。CourtneyはChatGPTの提案に従い、同様の症状を持つ子供たちの親が集まるFacebookグループに参加し、ChatGPTの診断の妥当性を確認した。その後、新たな神経外科医に相談し、ChatGPTの診断が正しいことを確認。Alexは手術を受け、現在は回復に向かっている。

## 3. ChatGPTの役割と診断プロセス

本事例におけるChatGPTの役割は、以下の通りである。

* **症状と検査結果の分析:** Courtneyが入力した息子のMRI検査結果と症状を分析し、可能性のある疾患を提示した。
* **情報提供:** 稀な疾患に関する情報を提示し、親が更なる情報を収集するための道筋を示した。
* **診断の補助:** 最終的な診断は医師が行ったものの、ChatGPTは診断の可能性を提示し、診断プロセスを加速させる役割を果たした。

## 4. AI技術の医療分野への影響と課題

本事例は、AI技術が医療分野において、診断の補助や情報提供に役立つ可能性を示唆している。しかし、同時に、以下の課題も存在する。

* **AIの限界:** AIはまだ発展途上の技術であり、誤った情報を生成する可能性（AIハルシネーション）がある。
* **医師との連携:** AIは医師の代わりになるものではなく、医師の診断を補助するツールとして活用されるべきである。
* **倫理的な問題:** AIの利用におけるプライバシー保護や、診断の公平性といった倫理的な問題への対応が必要である。

## 5. まとめ

本事例は、AI技術が医療分野において、診断の補助や情報提供に役立つ可能性を示す一方で、AIの限界や倫理的な課題も浮き彫りにしている。AI技術は、医師の診断を補助するツールとして、医療の質向上に貢献する可能性がある。しかし、その利用にあたっては、AIの特性を理解し、倫理的な問題にも配慮する必要がある。



**元記事:** [When 17 Doctors Fell Short, AI Stepped Up How ChatGPT Helped A Mother Diagnose Son's Rare Condition - News18](https://www.news18.com/world/when-17-doctors-couldnt-help-ai-did-how-chatgpt-helped-a-mother-diagnose-sons-rare-condition-ws-d-9299202.html)