# AppSOC Research LabsがDeepSeek-R1を企業利用に不向きと評価

## 緒言

本レポートでは、AppSOC Research Labsが発表したDeepSeek-R1に関する評価を基に、その内容を要約し、分析します。DeepSeek-R1は中国のAIスタートアップDeepSeekが開発した大規模言語モデル（LLM）であり、企業利用に適さないと判断されました。

## DeepSeek-R1の概要

DeepSeek-R1は、約670億のパラメータを持つ大規模言語モデルで、DeepSeekのチャットボットを支える技術です。このモデルは、米国の大手テック企業が提供するモデルに比べて低コストで提供されています。2025年初頭には、MicrosoftのAzure AI FoundryとGitHubで利用可能となりました。

## AppSOCの評価とテスト結果

AppSOC Research Labsは、Azure上でホストされているDeepSeek-R1をテストし、以下の主要なリスクを指摘しました。

### サプライチェーンリスク

DeepSeek-R1は、サプライチェーンの脅威カテゴリでテストされ、安全でないソフトウェアパッケージを推奨するなど、誤った情報を提供することが判明しました。Azureのフィルターを使用した場合、問題が悪化し、フィルターなしの5.8%からフィルターありの6.9%に失敗率が上昇しました。

### マルウェア生成

AIモデルは悪意のあるコードを生成すべきではありませんが、DeepSeek-R1はフィルターなしで96.7%、フィルターありでも93.8%の高い割合でマルウェア生成テストに失敗しました。これらの数値はAppSOCによって「危険に高い」と評価されています。

### プロンプトインジェクション

プロンプトインジェクションのテストでは、Azureのフィルターを使用しない場合の失敗率が57.1%、使用した場合でも40%と高く、企業利用には不適切とされています。

## リスク評価の詳細

AppSOCのテストでは、Azureのフィルターとガードレールを使用した場合と使用しない場合の両方で評価が行われました。フィルターを使用した場合、全体的なリスクスコアはわずかに改善しましたが、8.3/10から8.4/10へと微々たる変化でした。

| リスクカテゴリ | フィルターなしの失敗率 | フィルターありの失敗率 |
|-----------------------|------------------------|------------------------|
| サプライチェーンリスク | 5.8% | 6.9% |
| マルウェア生成 | 96.7% | 93.8% |
| プロンプトインジェクション | 57.1% | 40% |

## AppSOCの見解

AppSOCのチーフサイエンティストであり共同創業者のMali Gorantla氏は、「Azureのフィルターが一定の価値を提供するものの、DeepSeek-R1は企業利用に適さない高リスクモデルであることが確認された」と述べています。また、フィルターが一部のカテゴリではほとんど効果がなく、場合によってはモデルのパフォーマンスを悪化させる可能性があると指摘しています。

## 結論

DeepSeek-R1は、低コストで提供される大規模言語モデルとして注目を集めましたが、AppSOC Research Labsの評価によれば、企業利用には不向きであることが明らかになりました。特に、個人情報や機密データ、知的財産を扱うAIアプリケーションには使用すべきではないとされています。企業はAIモデルの選定に際して、セキュリティとリスク管理を重視する必要があります。

**元記事:** [AppSOC Research Labs Delivers Damning Verdict On DeepSeek-R1 ](https://informationsecuritybuzz.com/appsoc-research-verdict-on-deepseek-r1/)